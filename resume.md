# resume

标签（空格分隔）： personal

---

## 联系方式

- 手机: 15810037280
- Email: meiboyking7@163.com
- QQ: 151916524
- 微信号: error1573

---

## 个人信息

- 梅刚/男/1984.10
- 本科/武汉大学
- 工作年限: 9年(北京8年，上海1年)
- 期望职位: 大数据工程师, 系统架构师
- 期望城市: 上海

---

## 工作经历

### 上海

- 上海云熵网络科技有限公司  （2015.07-2016.07)

### 北京

- 风行网    (2012.09-2015.04)
- 百度      (2011.04-2012.04)
- 瑞星杀毒  (2009.05-2010.07)
- 中国建筑标准设计研究院金土木软件  (2007.07-2009.04)

---

## 个人素质综述
- 熟悉Windows和Linux系统开发
- 精通C++,Python, 熟悉Java,Scala
- 熟悉 Tornado/Django/Nginx/Redis/Mysql 等常用框架和基础组件, 以及其实现原理和工作特点。了解Spring Boot。
- 具有完备的技术体例，包括操作系统、网络、数据库、数据结构和算法,常用语言的差异等等。对IT一直以来的技术演化和产品变更有较清晰的认识。已形成一定程度的对技术的良好直觉。
- 熟悉常见服务器设计模型，对服务器高性能设计有较深刻认识。熟悉常见的服务器后台架构，包括模块拆分、负载均衡、面向服务重构、动静分离、前后端分离、RestFul/RPC，缓存等等
- 掌握基本的大数据平台架构，了解常用基础设施和中间件，包括Flume, Kafka, Spark/SparkStreaming, HDFS, Hive等。熟悉阿里云平台产品，包括 DataHub, ODPS, ONS等等。
- 具有累计三年的团队管理经验。善于营造团队气氛，凝聚开发力量，规划团队发展。
- 崇尚技术，乐于分享和布道，敢于打破现状提出想法。业务上敢于担当，勇于“填坑”，积极探索，打开局面。最重要的能力：解决问题的能力。最需要的机会：挑战。

---

## 项目经验 (依时间倒排)

### 数据平台
面向公司全方位的数据服务需要,综合提供数据采集、迁移、存储、计算/评估、对外消费结果等功能

- 职责
    数据平台组主管，带领开发和测试。负责平台的整体架构, 关键组件的设计及实现,核心部分件代码撰写等等
- 项目特点及成果
    1. 制定了灵活的日志格式，并约定了有效的日志文件记录方法和Linux平台的日志rotate模式。
    2. 支持HTTP模式日志上报的REST接口，支持多版本。同时支持JSON树状结构到线性日志的转换，并且框架依赖外部配置来调整转换逻辑，使得新添上报类型变得非常简单。
    3. Flume在日志源上的扩展，高效而稳定的支持数据迁移，利用checkpoint技术和幂等性实现记录的exact once. 利用Flume的监控接口实现数据迁移的监控，同时修改Flume源码实现记录类型的更细粒度的监控。
    4. 利用SchemaRegistry集中管理AVRO的Schema，扩展Flume的KafkaSink以支持AVRO格式的kafka写入。利用分布式的Confluent的Connector实现Kafka到HDFS的高可靠性导出，同时自定义partitioner以实现所需要粒度的数据分区。
    5. 实现SparkStreaming写入Kafka的基础组件。同时为了解决SpakrStreaming无Kafka消费上报导致无法监控，以及程序升级导致Checkpoint恢复失败的问题，添加了消费进度(Offset)上报Zookeeper的功能。同时，程序升级维护时，不从Checkpoint恢复，而是从Zookeeper获取Offset。
    6. 为了后续SparkSQL的离线计算效率和便捷性，在SparkStreaming中实现了部分清洗和Enrich功能(主要是为记录补充更多的相关信息的字段)。
    7. 为了便于部署，构建了配置服务器，以便动态下发配置给不同角色的服务器。配置服务器基于模板技术(tornado template)实现灵活构建。
    7. 构建了基本的监控和报警系统(利用微信公众号报警)，着重业务层面的监控。利用python采集数据和实施报警机制，同时利用redis实现RRD(round-robin database)功能。
    
### BOSS后台
提供给用户的视频和节点服务情况的CDN后台系统。

- 职责
  针对已有系统的架构整合(主要是后台系统)。
- 项目特点及成果
    1. 对耦合的功能进行拆分, 明确定义各模块的服务接口。包括前端服务器模块，上传模块，目录模块，用户以权限模块。当时的实现皆使用Node.js实现。
    2. 前后端交互部分采用了完全的分离模式，前端服务器负责整合后台的逻辑，并向FE提供Restful接口。
    3. 各基础模块之间亦有分层和依赖，其之间的接口当前尚为HTTP模式。用户和权限模块自定义了相对安全的机制和服务(类似阿里云OSS模式的鉴权)。
    
### 直播系统
以HLS (HTTP Live Streaming)模式提供全网的在线直播服务，同时支持网页Flash和APP端。 客户端之间，支持P2P传输。
无回看功能的直播: [http://www.fun.tv/live](http://www.fun.tv/live)
具有回看功能的地址: [http://www.smgbb.cn/tv/ ](http://www.smgbb.cn/tv/ )

- 职责
    负责后台CDN网络的架构设计和实现。
- 项目特点及成果
    1. 灵活快速的架构模式。系统采用了 Python + Nginx的模式, Python负责索引及动态请求部分, Nginx负责提供数据流访问。
    2. 重状态定制。为了支持直播回看和P2P分片传输的需要,根据数据的特点,索引部分采用了针对性设计的数据结构，以支持快速查找, 索引由进程内部维护。
    3. 磁盘IO的优化。原始的直播数据是切片连续同步，访问也是按切片为粒度访问，但大量小文件的存在使得访问和清理都效率低下。后采用了按一定粒度(回放保留的基本粒度)合并切片，文件访问则通过间接映射(以Range的方式反馈给Nginx)的方法进行。同时直播本身有连续性和集中性的特点，合并连续存储正好符合，能有效利用文件系统缓存。当然了，将文件系统指定为EXT4 。
    4. CDN节点同步进度优化。为了应对网络抖动，从静态分层同步转化为,多源并发分片同步，即p2p模式的同步。新的拓扑结构大幅提升了全网同步效果。此为最重要的改进。
    5. 支持防盗链的架构。利用Nginx的相对重定向功能，让所有对实体文件的请求都通过后台服务器过滤。后台服务器拦截请求后便可以对请求的合法性做判断。当然了，当前设计都是针对非登录用户，故而仅能通过算法校验，即校验请求源客户端软件的合法性而非客户身份。
    
### 视频聚合项目
制作影视大全的APP，索引主流视频网站的视频信息，并跟踪更新。

- 职责
    带领爬虫小组参与内容采集部分。
- 项目特点与成果
    1. 定向爬取网页的爬虫框架。最终的效果是：只要按约定形式撰写好各级页面的解析模块，框架便能够驱动整个流程运转起来。网络部分采用了异步长连接，连接池并发等手法，保证负载的饱和。对于网页分级下载，支持深度优先和广度优先的配置，权衡扩散度和囤积量。
    2. 利用浏览器调试技术破解各家视频网站的视频防盗链算法。
    3. 向APP动态下发LUA脚本，以实现在APP客户端上对视频下载地址的解析。
    4. 解决目录页页数有限(比如分页只支持20页)导致的提取数量不全的问题。

### UGC视频审核系统
该系统为视频生产系统,包括视频爬取和下载,视频上传,视频云转码,审核系统等组成 ,提供从其他视频网站抓取和用户自行上传两种视频来源渠道。

- 职责:
    项目经理
- 项目特点与成果
    1. 上马云转码系统大幅提升转码效率。基于业务瓶颈的压力，协同转码组兄弟利用媒体服务器空闲的CPU计算资源, 构建了全网的视频转码服务，以满足视频转码这种计算密集型业务的需要。
    2. 利用Django内置的权限管理模块，实现了丰富的角色权限控制。根据用户的操作流程和业务特点，网站针对性的设计，有效提高业务效率，包括丰富的截图和视频预览，快捷键操作，除了视频上传还提供转帖功能(提供URL，后台自动分析页面提取视频)等等。
    3. 视频内容中小视频部分存量大幅度提升，提高广告转化率，还没版权问题……。